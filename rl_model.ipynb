{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_adults_all = pd.read_csv(\"Study3_AAData_Adults.csv\", index_col = 0)\n",
    "aa_kids_all = pd.read_csv(\"Study3_AAData_Kids.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_of_interest = [\"PartID\", \"Block\", \"BadBlocks\", \"Trial\", \"Valence\", \"AA\", \"TrialSet\", \"Win\"]\n",
    "aa_kids = aa_kids_all[variables_of_interest]\n",
    "aa_adults = aa_adults_all[variables_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(aa_kids[\"PartID\"])\n",
    "aa_kids = aa_kids.sort_values(by=['PartID', 'Trial'])\n",
    "aa_adults = aa_adults.sort_values(by=['PartID', 'Trial'])\n",
    "print(aa_adults['PartID'].unique())\n",
    "# an invalid action at line 406\n",
    "print(aa_adults[aa_adults[\"AA\"].isnull()])\n",
    "aa_adults.at[406, 'AA'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aa_kids['Block'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL_LLH(param, Data): \n",
    "    \"\"\"\n",
    "    [llh] = RL_LLH(param) computes the negative log-likelihood of the data given \n",
    "        the model specified above, and the parameters parm. \n",
    "    \n",
    "    param[0], beta, is the softmax temperature of the RL policy\n",
    "    param[1], alpha, is the learning rate of the RL agent\n",
    "    \n",
    "    Data is a [n * 40 * 2, 6] array containing the data generated by the agent. \n",
    "    Data[:, 0] is the block number, from {1, ..., n}, at each trial\n",
    "    Data[:, 1] is the phase number, from {1, 2}, at each trial\n",
    "    Data[:, 2] is the trial number in a block, from {1, ..., N} \n",
    "    Data[:, 3] is the agent's choice, from {1, 2}, at each trial\n",
    "    Data[:, 4] is the feedback received by the agent at each trial, from {0, 1}\n",
    "    Data[:, 5] indicates whether the choice is correct, from {0, 1}\n",
    "    \n",
    "    nllh = -llh is the negative log likelihood. \n",
    "    \"\"\"\n",
    "    \n",
    "    beta = param[0]\n",
    "    alpha = {\"C\": param[1], \"P\": param[2], \"PC\": param[3], \"PP\": param[4]}\n",
    "    #eps = param[3]\n",
    "    #alpha = param[1]\n",
    "    \n",
    "    # Task Parameters \n",
    "    #N = int(np.max(Data[:, 2])) + 1 # number of trials in a block\n",
    "    #n = int(np.max(Data[:, 0])) + 1 # number of blocks (trial sets)\n",
    "    llh = 0\n",
    "    \n",
    "    k = 0 \n",
    "    \n",
    "    for block in range(48): \n",
    "        Q = {\"B\": 1, \"W\": 1, \"P\": 1, \"S\": 1}\n",
    "        #Q = np.array([.5, .5])\n",
    "        for trial in range(16): \n",
    "            vals = np.fromiter(Q.values(), dtype=float)\n",
    "            softmax = {\"BS\": 0.25, \"WS\": 0.25, \"BP\": 0.25, \"WS\": 0.25}\n",
    "            softmax[\"WS\"] = 1 / sum(np.exp(beta * (vals - Q['W']*Q['S'])))\n",
    "            softmax[\"WP\"] = 1 / sum(np.exp(beta * (vals- Q['P']*Q['W'])))\n",
    "            softmax[\"BS\"] = 1 / sum(np.exp(beta * (vals - Q['S']*Q['B'])))\n",
    "            softmax[\"BP\"] = 1 - softmax[\"BS\"] - softmax[\"WP\"] - softmax[\"WS\"]\n",
    "         \n",
    "\n",
    "            action = int(Data.iloc[k]['AA'])\n",
    "            reward = Data.iloc[k]['Win']\n",
    "            actual = Data.iloc[k]['Valence']\n",
    "            block = Data.iloc[k]['Block']\n",
    "\n",
    "\n",
    "            if action == 1:\n",
    "                # update the values \n",
    "                if reward == 0: \n",
    "                    reward = -2\n",
    "                    Q[block[0]] += alpha['C'] * (reward - Q[block[0]])\n",
    "                    Q[block[1]] += alpha['P'] * (reward - Q[block[1]])\n",
    "                else:\n",
    "                    Q[block[0]] += alpha['PC'] * (reward - Q[block[0]])\n",
    "                    Q[block[1]] += alpha['PP'] * (reward - Q[block[1]])\n",
    "\n",
    "            #else:\n",
    "                #Q[block[0]] += alpha['C'] * (actual - 1)\n",
    "                #Q[block[1]] += alpha['P'] * (actual - 1)\n",
    "            # update the log likelihood\n",
    "            #print(softmax[block]) \n",
    "            print(softmax[block])\n",
    "            llh += np.log(softmax[block])\n",
    "            # update the iteration counter\n",
    "            k+=1\n",
    "        #print(Data.iloc[k-16:k-1])\n",
    "        #print(\"current state of Q: \",Data.iloc[k-1]['BadBlocks'], Q, softmax, llh)\n",
    "    \n",
    "    return -llh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Not sure what this means (adult): \", RL_LLH([.5, 1, 1, 1, 5], aa_adults))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Not sure what this means (kids): \", RL_LLH([0.5, 0.1, 0.1, 0.01, 0.05], aa_kids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(fname, \n",
    "             bounds, \n",
    "             Data, \n",
    "             niter,\n",
    "             toplot=False,\n",
    "            ):\n",
    "             \n",
    "    #  bestparameters,bestllh = optimize(fname,bounds, Data,niter,toplot) runs \n",
    "    #  the minimize function niter times on the function fname, with constraints \n",
    "    #  bounds to find parameters that best fit the data Data. It returns the\n",
    "    #  best likelihood and best fit parameters over the niter iterations.\n",
    "\n",
    "    #  ## fname is the python function to optimize. fname \n",
    "    #  should take as first argument a 1 by n vector of parameters. \n",
    "    #  Note the bounds are set up differently than they are in Matlab, \n",
    "    #  And should come as a list of [min,max] pairs. (ie. [[min,max],[min,max], ...])\n",
    "    #  \n",
    "    #  ## Data is the data set to be fit by likelihood function fname.\n",
    "    #  ## niter is the number of starting points for the optimization\n",
    "    #  ## toplot is an optional argument; if plot~=0, this function will plot the\n",
    "    #  best likelihood as a function of starting point iterations.\n",
    "\n",
    "    #  ## best parameters is the 1*n vector of parameters found to minimize the\n",
    "    #  negative log likelihood over the data.\n",
    "    #  bestllh is the log likelihood value for the best parameters.\n",
    "\n",
    "    outcomes = np.full([niter, len(bounds)+1], np.nan)\n",
    "    optimcurve = np.full(niter, np.nan)\n",
    "    for i in range(niter):\n",
    "        \n",
    "        # random starting point based on maximum bounds\n",
    "        params0 = np.array([bound[1] * np.random.rand() for bound in bounds])\n",
    "            \n",
    "        # compute the function value at the starting point\n",
    "        llh0 = fname(params0, Data)\n",
    "        \n",
    "        # run the optimizer with constraints\n",
    "        result = minimize(fun=fname, x0=params0, args=(Data), bounds=bounds)\n",
    "        x = result.x\n",
    "        bestllh = fname(x, Data)\n",
    "        outcomes[i, :] = [bestllh] + [xi for xi in x]    \n",
    "        optimcurve[i] = min(outcomes[:(i+1), 0])\n",
    "    print(outcomes)\n",
    "    # find the global minimum out of all outcomes\n",
    "    i = np.argwhere(outcomes[:, 0] == np.min(outcomes[:, 0]))\n",
    "    bestparameters = outcomes[i[0], 1:].flatten()\n",
    "    bestllh = -1 * outcomes[i[0], 0].flatten()[0]\n",
    "    \n",
    "    # plot the best llh found by the optimizer as a function of iteration number.\n",
    "    if toplot:\n",
    "        plt.figure()\n",
    "        plt.plot(range(niter), np.round(optimcurve, 6), 'o-')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('best minimum')\n",
    "        plt.title('Negative log likelihood')\n",
    "    \n",
    "    return(bestparameters, bestllh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "betamin = 0\n",
    "betamax = 20 \n",
    "alpha0min = 0\n",
    "alpha0max = .1\n",
    "alpha1min = 0\n",
    "alpha1max = .1\n",
    "bounds = [[betamin, betamax], [alpha0min, alpha0max], [alpha1min, alpha1max], [alpha1min, alpha1max], [alpha1min, alpha1max]]\n",
    "niter = 20\n",
    "nblocks = 4\n",
    "\n",
    "bestparameters, bestllh = optimize(RL_LLH, bounds, aa_adults, niter, toplot=True)\n",
    "\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha0 is {0}'.format(bestparameters[1]))\n",
    "print('best alpha1 is {0}'.format(bestparameters[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as model: # model specifications in PyMC3 are wrapped in a with-statement\n",
    "# Define priors: trying slightly more informative priors\n",
    "    alpha = Beta('alpha', 2, 4) # how much simpler hypotheses are favored\n",
    "    error = Gamma('error', 5, 1) # how \"rationally\" people follow the choice rule\n",
    "    shift = TruncatedNormal('shift', 0, 0.3, lower = -2, upper = 1) # how \"risky\"/\"safe\" people are\n",
    "\n",
    "    priors = np.repeat(np.array([alpha/4, (1-alpha)/4]), 4) #make priors based on alpha parameter\n",
    "\n",
    "#     define likelihoods\n",
    "    likBPgood = np.array([0, 1, 0, 1, 0, 1, 1, 1])\n",
    "    likBSgood = np.array([0, 1, 1, 0, 1, 0, 1, 1])\n",
    "    likWPgood = np.array([1, 0, 0, 1, 1, 1, 0, 1])\n",
    "    likWSgood = np.array([1, 0, 1, 0, 1, 1, 1, 0])\n",
    "\n",
    "    likBPbad = np.array([1, 0, 1, 0, 1, 0, 0, 0])\n",
    "    likBSbad = np.array([1, 0, 0, 1, 0, 1, 0, 0])\n",
    "    likWPbad = np.array([0, 1, 1, 0, 0, 0, 1, 0])\n",
    "    likWSbad = np.array([0, 1, 0, 1, 0, 0, 0, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
