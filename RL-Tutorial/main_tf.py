import gym
from dqn_tf import DeepQNetwork
import numpy as np
from gym import wrappers 

def preprocess(observation): 
        """
        Extract only the relevant portions of the image, removing info such 
        as the scoreboard, etc. 
        """
        return np.mean(observation[30:, :], axis = 2).reshape(180, 160, 1)

def stack_frames(stacked_frames, frame, buffer_size):
        """
        Stack the frames to provide information about motion. 

        Inputs: 
                - stacked_frames: None if there are no simulations yet, 
                        otherwise it is a numpy array storing the 
                        frames that have been observed already
                - 
                - buffer_size: the number of frames to be stacked in 
                        order to provide the motion information
        """

        # if the stacked frame is empty currently, take in the next 
        # buffer size worth of frames to populate it 
        if stacked_frames is None: 
                stacked_frames = np.zeros((buffer_size, *frame.shape))
                for idx, _ in enumerate(stacked_frames): 
                        stacked_frames[idx, :] = frame
        else: # otherwise, pop oldest and append new frame
                stacked_frames[0:buffer_size-1, :] = stacked_frames[1:, :]
                stacked_frames[buffer_size-1, :] = frame
        # reshape for neural network
        stacked_frames = stacked_frames.reshape(1, *frame.shape[0:2], buffer_size)
        return stacked_frames

if __name__ == '__main__': 
        env = gym.make('Breakout-v0')
        load_checkpoint = False
        agent = DeepQNetwork.Agent(gamma = 0.99, epsilon = 1.0, alpha = 0.00025, input_dims = (180, 160, 4), 
                      n_actions = 3, mem_size = 2500, batch_size = 32)
        if load_checkpoint: 
                agent.load_models()
        scores = []
        numGames = 200
        stack_size = 4
        score = 0

        # loading the agent with random memories 
        while agent.mem_cntr < 25000: 
                done = False
                observation = env.reset()
                observation = preprocess(observation)
                stacked_frames = None
                observation = stack_frames(stacked_frames, observation, stack_size)
                while not done: 
                        action = np.random.choice([0, 1, 2])
                        action += 1
                        observation_, reward, done, info = env.step(action)
                        observation_ = stack_frames(stack_frames, preprocess(observation_), stack_size)
                        action -= 1
                        agent.store_transition(observation, action, reward, observation_, int(done))
                        observation = observation_

        print("Done with random game play, game on.")

        # play the game!
        for i in range(numGames): 
                done = False
                if i % 10 == 0 and i > 0: 
                        avg_score = np.mean(scores[max(0, i - 10):(i + 1)]) 
                        print('episode', i, 'score', score, 'average_score %.3f' % avg_score, 
                        'epsilon %.3f' % agent.epsilon)
                        agent.save_models()
                else: 
                        print('episode: ', i, 'score', score)

                observation = env.reset()
                observation = preprocess(observation)
                stacked_frames = None
                observation = stack_frames(stacked_frames, observation, stack_size)
                while not done: 
                        action = agent.choose_action(observation)
                        action += 1
                        observation_, reward, done, info = env.step(action)
                        observation_ = stack_frames(stack_frames, preprocess(observation_), stack_size)
                        action -= 1
                        agent.store_transition(observation, action, reward, observation_, int(done))
                        observation = observation_
                        agent.learn()
                        score+=reward
                        
                scores.append(score)


                        


