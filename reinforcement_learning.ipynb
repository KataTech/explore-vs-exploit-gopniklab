{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc8a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from mpl_toolkits import mplot3d\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbbf68",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "--\n",
    "The goal of this section is to prepare the data into the format necessary for RL modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16701dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartID         int64\n",
      "Block         object\n",
      "BadBlocks     object\n",
      "Trial          int64\n",
      "TrialSet       int64\n",
      "Valence        int64\n",
      "AA             int64\n",
      "Win          float64\n",
      "dtype: object \n",
      "\n",
      "PartID         int64\n",
      "Block         object\n",
      "BadBlocks     object\n",
      "Trial          int64\n",
      "TrialSet       int64\n",
      "Valence        int64\n",
      "AA             int64\n",
      "Win          float64\n",
      "dtype: object \n",
      "\n",
      "PartID         int64\n",
      "Block         object\n",
      "BadBlocks     object\n",
      "Trial          int64\n",
      "TrialSet       int64\n",
      "Valence        int64\n",
      "AA             int64\n",
      "Win          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read in the data sets from the approach/avoid task\n",
    "aa_adults = pd.read_csv(\"Study3_AAData_Adults.csv\", index_col = 0)\n",
    "aa_kids = pd.read_csv(\"Study3_AAData_Kids.csv\", index_col = 0)\n",
    "\n",
    "# subset by a preliminary set of interesting variables \n",
    "variables_of_interest = [\"PartID\", \"Block\", \"BadBlocks\", \"AgeGroup\", \"Trial\", \"TrialSet\", \"Valence\", \"AA\", \"Win\"]\n",
    "aa_adults = aa_adults[variables_of_interest]\n",
    "aa_kids = aa_kids[variables_of_interest]\n",
    "\n",
    "# modify the \"Win\" columns to capture the true Reward in terms of stickers/dollars\n",
    "aa_kids.loc[aa_kids.Win == 0, \"Win\"] = -2\n",
    "aa_kids.loc[aa_kids.AA == 0, \"Win\"] = 0\n",
    "aa_adults.loc[aa_adults.Win == 0, \"Win\"] = -2\n",
    "aa_adults.loc[aa_adults.AA == 0, \"Win\"] = 0\n",
    "\n",
    "# separate into kids_young, kids_old, adults \n",
    "aa_kids_young = aa_kids[aa_kids.AgeGroup == \"Young\"].copy()\n",
    "aa_kids_old = aa_kids[aa_kids.AgeGroup == \"Old\"].copy()\n",
    "\n",
    "# drop the AgeGroup column since they are meaningless \n",
    "aa_kids_young.drop(columns = [\"AgeGroup\"], inplace = True)\n",
    "aa_kids_old.drop(columns = [\"AgeGroup\"], inplace = True)\n",
    "aa_adults.drop(columns = [\"AgeGroup\"], inplace = True)\n",
    "\n",
    "# encode the kid participant IDs as numerics \n",
    "ptcp = 1\n",
    "ptcp_to_num_young = {}\n",
    "for participant in set(aa_kids_young.PartID): \n",
    "    ptcp_to_num_young[participant] = ptcp\n",
    "    ptcp += 1\n",
    "aa_kids_young.replace({\"PartID\": ptcp_to_num_young}, inplace = True)\n",
    "\n",
    "ptcp = 1\n",
    "ptcp_to_num_old = {}\n",
    "for participant in set(aa_kids_old.PartID): \n",
    "    ptcp_to_num_old[participant] = ptcp\n",
    "    ptcp += 1\n",
    "aa_kids_old.replace({\"PartID\": ptcp_to_num_old}, inplace = True)\n",
    "\n",
    "# sort each dataframe by participant ID and then Trial\n",
    "aa_kids_young.sort_values(by = [\"PartID\", \"Trial\"], inplace = True)\n",
    "aa_kids_old.sort_values(by = [\"PartID\", \"Trial\"], inplace = True)\n",
    "aa_adults.sort_values(by = [\"PartID\", \"Trial\"], inplace = True)\n",
    "\n",
    "# Check for NA Values\n",
    "variables_of_interest = [\"PartID\", \"Block\", \"BadBlocks\", \"Trial\", \"TrialSet\", \"Valence\", \"AA\", \"Win\"]\n",
    "aa_kids_young.loc[aa_kids_young[variables_of_interest].isna().any(axis=1), variables_of_interest] # Good!\n",
    "aa_kids_old.loc[aa_kids_old[variables_of_interest].isna().any(axis=1), variables_of_interest] # Good!\n",
    "aa_adults.loc[aa_adults[variables_of_interest].isna().any(axis=1), variables_of_interest] # abnormal entry spotted\n",
    "aa_adults.drop(index = 406, inplace = True) # drop the bad entry \n",
    "aa_adults[[\"AA\"]] = aa_adults[[\"AA\"]].astype(int) # prevent error indexing \n",
    "\n",
    "# reset the index after re-ordering\n",
    "aa_kids_young.reset_index(inplace = True, drop = True)\n",
    "aa_kids_old.reset_index(inplace = True, drop = True)\n",
    "aa_adults.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# verify the datatypes \n",
    "print(aa_kids_young.dtypes, \"\\n\")\n",
    "print(aa_kids_old.dtypes, \"\\n\")\n",
    "print(aa_adults.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43125986",
   "metadata": {},
   "source": [
    "## Utility Functions: Optimization, Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a078df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_llh_by_params(fname, bounds, Data, plot = 'contour', color_map = 'viridis'): \n",
    "    \"\"\"\n",
    "    Create a 3D-plot of log-likelihood distribution based on the specified \n",
    "    bounds. \n",
    "    \"\"\"\n",
    "    beta_vector = np.linspace(bounds[0][0], bounds[0][1], 30)\n",
    "    alpha_vector = np.linspace(bounds[1][0], bounds[1][1], 30)\n",
    "    llh = np.full([30, 30], np.nan)\n",
    "    for i in range(30): \n",
    "        for j in range(30): \n",
    "            llh[i][j] = fname(np.array([beta_vector[i], alpha_vector[j]]), Data)\n",
    "    Beta, Alpha = np.meshgrid(beta_vector, alpha_vector)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    if plot == \"contour\": \n",
    "        ax.contour3D(Beta, Alpha, llh, 50, cmap=color_map)\n",
    "    elif plot == \"surface\": \n",
    "        ax.plot_surface(Beta, Alpha, llh, cmap = color_map)\n",
    "    ax.set_xlabel('beta')\n",
    "    ax.set_ylabel('alpha')\n",
    "    ax.set_zlabel('negative log likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ebf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(fname, \n",
    "             bounds, \n",
    "             Data, \n",
    "             niter,\n",
    "             toplot=False, \n",
    "             message=False\n",
    "            ):\n",
    "            \n",
    "    \"\"\"\n",
    "    bestparameters,bestllh = optimize(fname, bounds, Data, niter, toplot) runs \n",
    "    the minimize function niter times on the function fname, with constraints \n",
    "    bounds to find parameters that best fit the data Data. It returns the \n",
    "    best likelihood and best fit parameters over the niter iterations.\n",
    "\n",
    "    ## fname is the python function to optimize. fname \n",
    "    should take as first argument a 1 by n vector of parameters. \n",
    "    Note the bounds are set up differently than they are in Matlab, \n",
    "    And should come as a list of [min,max] pairs. (ie. [[min,max],[min,max], ...])\n",
    "     \n",
    "    ## Data is the data set to be fit by likelihood function fname.\n",
    "    ## niter is the number of starting points for the optimization\n",
    "    ## toplot is an optional argument; if plot~=0, this function will plot the\n",
    "    best likelihood as a function of starting point iterations.\n",
    "    \n",
    "    ## best parameters is the 1*n vector of parameters found to minimize the\n",
    "    negative log likelihood over the data.\n",
    "    bestllh is the log likelihood value for the best parameters.\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    outcomes = np.full([niter, len(bounds)+1], np.nan)\n",
    "    optimcurve = np.full(niter, np.nan)\n",
    "    for i in range(niter):\n",
    "        \n",
    "        if message: \n",
    "            if (int(niter * 0.10) == i): \n",
    "                print(\"Processed 10% ....\")\n",
    "            elif (int(niter * 0.20) == i): \n",
    "                print(\"Processed 20% ....\")\n",
    "            elif (int(niter * 0.30) == i): \n",
    "                print(\"Processed 30% ....\")\n",
    "            elif (int(niter * 0.40) == i): \n",
    "                print(\"Processed 40% ....\")\n",
    "            elif (int(niter * 0.50) == i): \n",
    "                print(\"Processed 50% ....\")\n",
    "            elif (int(niter * 0.60) == i): \n",
    "                print(\"Processed 60% ....\")\n",
    "            elif (int(niter * 0.70) == i): \n",
    "                print(\"Processed 70% ....\")\n",
    "            elif (int(niter * 0.80) == i): \n",
    "                print(\"Processed 80% ....\")\n",
    "            elif (int(niter * 0.90) == i): \n",
    "                print(\"Processed 90% ....\")\n",
    "        \n",
    "        # random starting point based on maximum bounds\n",
    "        params0 = np.array([bound[1] * np.random.rand() for bound in bounds])\n",
    "            \n",
    "        # compute the function value at the starting point\n",
    "        llh0 = fname(params0, Data)\n",
    "        \n",
    "        # run the optimizer with constraints\n",
    "        result = minimize(fun=fname, x0=params0, args=(Data), bounds=bounds)\n",
    "        x = result.x\n",
    "        bestllh = fname(x, Data)\n",
    "        outcomes[i, :] = [bestllh] + [xi for xi in x]    \n",
    "        optimcurve[i] = min(outcomes[:(i+1), 0])\n",
    "\n",
    "    if message: \n",
    "        print(\"Completed iterations... now compiling results...\")\n",
    "    \n",
    "    # find the global minimum out of all outcomes\n",
    "    i = np.argwhere(outcomes[:, 0] == np.min(outcomes[:, 0]))\n",
    "    bestparameters = outcomes[i[0], 1:].flatten()\n",
    "    bestllh = -1 * outcomes[i[0], 0].flatten()[0]\n",
    "    \n",
    "    # plot the best llh found by the optimizer as a function of iteration number.\n",
    "    if toplot:\n",
    "        plt.figure()\n",
    "        plt.plot(range(niter), np.round(optimcurve, 6), 'o-')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('best minimum')\n",
    "        plt.title('Negative log likelihood')\n",
    "    \n",
    "    return(bestparameters, bestllh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78177f4",
   "metadata": {},
   "source": [
    "## Modeling Functions: Generative and Model-Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e44e0f",
   "metadata": {},
   "source": [
    "### Generative Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0db52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL_StateAction(param, numParticipants, trialSets): \n",
    "    \"\"\"\n",
    "    Generates simulated data with the two-factor Q-learning model, i.e. the Q function \n",
    "    takes as input both the block currently presented to the participant and the action \n",
    "    available to them overtime. This is an extension/modification of the RL function. \n",
    "    \"\"\"\n",
    "    # set-up\n",
    "    beta = param[0]\n",
    "    alpha = param[1]\n",
    "    blocks = np.array([\"BP\", \"BS\", \"WP\", \"WS\"])\n",
    "    rewards = np.array([-2.0, 1.0])\n",
    "    Data = np.ones(5)\n",
    "        \n",
    "    for participant in range(1, numParticipants + 1): \n",
    "        trial = 1 # counter for the trial number\n",
    "        bad_block_idx = np.random.choice(4) # select a bad block for the current participant\n",
    "        Q = np.full((2, 4), 0.5) # set up Q-function\n",
    "        Q[0, :] = 0.0\n",
    "        Q[1, :] = -0.5\n",
    "        # first trial set - the first two blocks are shown and the second must be non-zaff\n",
    "        good_block_idx = np.delete(np.random.permutation(4), bad_block_idx)\n",
    "        for i in range(4): \n",
    "            if i == 0: \n",
    "                block_idx = good_block_idx[i]; action = 1; reward = rewards[1];\n",
    "                Q[action, block_idx] += alpha * (reward - Q[action, block_idx])\n",
    "            elif i == 1: \n",
    "                block_idx = bad_block_idx; action = 1; reward = rewards[0]; \n",
    "                Q[action, block_idx] += alpha * (reward - Q[action, block_idx])\n",
    "            else: \n",
    "                block_idx = good_block_idx[i - 1]\n",
    "                softmax = np.array([0.5, 0.5])\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                action = np.random.choice(range(2), p=softmax)\n",
    "                if action == 0: # avoid\n",
    "                    reward = 0 \n",
    "                else: # approach\n",
    "                    reward = rewards[int(block_idx != bad_block_idx)]\n",
    "                    Q[action, block_idx] += alpha * (reward - Q[action, block_idx])\n",
    "            Data = np.vstack((Data, \n",
    "                              np.array([participant, trial, action, reward, blocks[block_idx]], dtype = object)))\n",
    "            trial += 1\n",
    "        # subsequent trial set \n",
    "        for trialset in range(2, trialSets + 1): \n",
    "            for block_idx in np.random.permutation(4): \n",
    "                # determine approach vs. avoid - bernoulli trial\n",
    "                softmax = np.array([0.5, 0.5])\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                action = np.random.choice(range(2), p=softmax)\n",
    "                # update values depending on action\n",
    "                if action == 0: # avoid\n",
    "                    reward = 0 \n",
    "                else: # approach\n",
    "                    reward = rewards[int(block_idx != bad_block_idx)]\n",
    "                    Q[action, block_idx] += alpha * (reward - Q[action, block_idx])\n",
    "                # store the data\n",
    "                Data = np.vstack((Data, \n",
    "                                  np.array([participant, trial, action, reward, blocks[block_idx]], dtype = object)))\n",
    "                trial += 1\n",
    "                \n",
    "    return Data[1:]  # remove first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a91854d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL2a_StateAction(param, numParticipants, trialSets): \n",
    "    \"\"\"\n",
    "    Generates simulated data with the two-factor Q-learning model, i.e. the Q function \n",
    "    takes as input both the block currently presented to the participant and the action \n",
    "    available to them overtime. This is an extension/modification of the RL function. \n",
    "    \"\"\"\n",
    "    # set-up\n",
    "    beta = param[0]\n",
    "    alpha_pos = param[1]\n",
    "    alpha_neg = param[2]\n",
    "    blocks = np.array([\"BP\", \"BS\", \"WP\", \"WS\"])\n",
    "    rewards = np.array([-2.0, 1.0])\n",
    "    Data = np.ones(5)\n",
    "        \n",
    "    for participant in range(1, numParticipants + 1): \n",
    "        trial = 1 # counter for the trial number\n",
    "        bad_block_idx = np.random.choice(4) # select a bad block for the current participant\n",
    "        Q = np.full((2, 4), 0.5) # set up Q-function\n",
    "        Q[0, :] = 0.0\n",
    "        Q[1, :] = -0.5\n",
    "        # first trial set - the first two blocks are shown and the second must be non-zaff\n",
    "        good_block_idx = np.delete(np.random.permutation(4), bad_block_idx)\n",
    "        for i in range(4): \n",
    "            if i == 0: \n",
    "                block_idx = good_block_idx[i]; action = 1; reward = rewards[1];\n",
    "                Q[action, block_idx] += alpha_pos * (reward - Q[action, block_idx])\n",
    "            elif i == 1: \n",
    "                block_idx = bad_block_idx; action = 1; reward = rewards[0]; \n",
    "                Q[action, block_idx] += alpha_neg * (reward - Q[action, block_idx])\n",
    "            else: \n",
    "                block_idx = good_block_idx[i - 1]\n",
    "                softmax = np.array([0.5, 0.5])\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                action = np.random.choice(range(2), p=softmax)\n",
    "                if action == 0: # avoid\n",
    "                    reward = 0 \n",
    "                else: # approach\n",
    "                    reward = rewards[int(block_idx != bad_block_idx)]\n",
    "                    Q[action, block_idx] += alpha_pos * (reward - Q[action, block_idx])\n",
    "            Data = np.vstack((Data, \n",
    "                              np.array([participant, trial, action, reward, blocks[block_idx]], dtype = object)))\n",
    "            trial += 1\n",
    "        # subsequent trial set \n",
    "        for trialset in range(2, trialSets + 1): \n",
    "            for block_idx in np.random.permutation(4): \n",
    "                # determine approach vs. avoid - bernoulli trial\n",
    "                softmax = np.array([0.5, 0.5])\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                action = np.random.choice(range(2), p=softmax)\n",
    "                # update values depending on action\n",
    "                if action == 0: # avoid\n",
    "                    reward = 0 \n",
    "                else: # approach\n",
    "                    reward = rewards[int(block_idx != bad_block_idx)]\n",
    "                    if reward > 0: \n",
    "                        Q[action, block_idx] += alpha_pos * (reward - Q[action, block_idx])\n",
    "                    else: \n",
    "                        Q[action, block_idx] += alpha_neg * (reward - Q[action, block_idx])\n",
    "                # store the data\n",
    "                Data = np.vstack((Data, \n",
    "                                  np.array([participant, trial, action, reward, blocks[block_idx]], dtype = object)))\n",
    "                trial += 1\n",
    "                \n",
    "    return Data[1:]  # remove first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae524b06",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimation Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a33e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL_StateAction_LLH(param, Data): \n",
    "    \"\"\"\n",
    "    This function is the loglikelihood function for a simple RL model with both state and action \n",
    "    build into the decision process. Specifically, the Q function takes as input both the block \n",
    "    currently presented to the participant and the action available to them. \n",
    "    \"\"\"\n",
    "    beta = param[0]\n",
    "    alpha = param[1] \n",
    "    n = int(np.max(Data[:, 0])) # number of participants \n",
    "    llh = 0 # log-likelihood \n",
    "    k = 0 # iteration tracker\n",
    "    blocks = {\"BP\": 0, \"BS\": 1, \"WP\": 2, \"WS\": 3}\n",
    "    \n",
    "    for participant in range(1, n + 1): \n",
    "        # set up Q-function\n",
    "        Q = np.full((2, 4), np.nan)\n",
    "        Q[0, :] = 0\n",
    "        Q[1, :] = -0.5\n",
    "        for trial in Data[Data[:, 0] == participant, 1]: \n",
    "            # set trial outcomes \n",
    "            action = Data[k, 2]\n",
    "            reward = Data[k, 3]\n",
    "            block = Data[k, 4]\n",
    "            block_idx = blocks[block]\n",
    "            # ignore the first two trials for loglikelihood computation\n",
    "            if trial > 2: \n",
    "                # compute softmax probabilities\n",
    "                softmax = np.full(2, np.nan)\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                # update the loglikelihood \n",
    "                llh += np.log(softmax[int(action)])\n",
    "            # update Q-value if the block was approached\n",
    "            if action == 1: \n",
    "                Q[action, block_idx] += alpha * (reward - Q[action, block_idx])\n",
    "            # update iteration counter\n",
    "            k += 1\n",
    "            \n",
    "    return -llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9997854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RL2a_StateAction_LLH(param, Data): \n",
    "    \"\"\"\n",
    "    This function is the loglikelihood function for a simple RL model with both state and action \n",
    "    build into the decision process. Specifically, the Q function takes as input both the block \n",
    "    currently presented to the participant and the action available to them. \n",
    "    \"\"\"\n",
    "    beta = param[0]\n",
    "    alpha_pos = param[1] \n",
    "    alpha_neg = param[2]\n",
    "    n = int(np.max(Data[:, 0])) # number of participants \n",
    "    llh = 0 # log-likelihood \n",
    "    k = 0 # iteration tracker\n",
    "    blocks = {\"BP\": 0, \"BS\": 1, \"WP\": 2, \"WS\": 3}\n",
    "    \n",
    "    for participant in range(1, n + 1): \n",
    "        # set up Q-function\n",
    "        Q = np.full((2, 4), np.nan)\n",
    "        Q[0, :] = 0\n",
    "        Q[1, :] = -0.5\n",
    "        for trial in Data[Data[:, 0] == participant, 1]: \n",
    "            # set trial outcomes \n",
    "            action = Data[k, 2]\n",
    "            reward = Data[k, 3]\n",
    "            block = Data[k, 4]\n",
    "            block_idx = blocks[block]\n",
    "            # ignore the first two trials for loglikelihood computation\n",
    "            if trial > 2: \n",
    "                # compute softmax probabilities\n",
    "                softmax = np.full(2, np.nan)\n",
    "                softmax[0] = 1 / np.sum(np.exp(beta * (Q[:, block_idx] - Q[0, block_idx])))\n",
    "                softmax[1] = 1 - softmax[0]\n",
    "                # update the loglikelihood \n",
    "                llh += np.log(softmax[int(action)])\n",
    "            # update Q-value if the block was approached\n",
    "            if action == 1: \n",
    "                if reward > 0: \n",
    "                    Q[action, block_idx] += alpha_pos * (reward - Q[action, block_idx])\n",
    "                else: \n",
    "                    Q[action, block_idx] += alpha_neg * (reward - Q[action, block_idx])\n",
    "            # update iteration counter\n",
    "            k += 1\n",
    "            \n",
    "    return -llh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce52ec",
   "metadata": {},
   "source": [
    "## Experiments: Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e4e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "np.random.seed(1868)\n",
    "betamin = 0\n",
    "betamax = 1\n",
    "alphamin = 0\n",
    "alphamax = 1\n",
    "niter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c04cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Fitting with Fabricated Data \n",
    "np.random.seed(1868)\n",
    "beta = 5\n",
    "alpha = 0.4\n",
    "param = [beta, alpha]\n",
    "Data = RL_StateAction(param, 40, 4).to_numpy()\n",
    "\n",
    "# set up the optimizer\n",
    "betamin = 0\n",
    "betamax = 10\n",
    "alphamin = 0\n",
    "alphamax = 1\n",
    "bounds = [[betamin, betamax], [alphamin, alphamax]]\n",
    "niter = 20\n",
    "\n",
    "nllh_trueparams = RL_StateAction_LLH([beta, alpha], Data)\n",
    "llh_trueparams = -1 * nllh_trueparams\n",
    "\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "\n",
    "print()\n",
    "print('overall')\n",
    "print('loglikelihood for true params is {0}, best loglikelihood is {1}'.format(llh_trueparams, bestllh))\n",
    "print('true beta is {0}, recovered beta is {1}'.format(beta, bestparameters[0]))\n",
    "print('true alpha is {0}, recovered alpha is {1}'.format(alpha, bestparameters[1]))\n",
    "\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ea2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the 2 Alpha Generating and Loglikelihood Functions\n",
    "np.random.seed(1868)\n",
    "beta = 5\n",
    "alpha_pos = 0.8\n",
    "alpha_neg = 0.3\n",
    "param = [beta, alpha_pos, alpha_neg]\n",
    "Data = RL2a_StateAction(param, 40, 4).to_numpy()\n",
    "\n",
    "# set up the optimizer\n",
    "betamin = 0\n",
    "betamax = 10\n",
    "alphamin = 0\n",
    "alphamax = 1\n",
    "bounds = [[betamin, betamax], [alphamin, alphamax], [alphamin, alphamax]]\n",
    "niter = 10\n",
    "\n",
    "nllh_trueparams = RL_StateAction_LLH([beta, alpha], Data)\n",
    "llh_trueparams = -1 * nllh_trueparams\n",
    "\n",
    "bestparameters, bestllh = optimize(RL2a_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "\n",
    "print()\n",
    "print('overall')\n",
    "print('loglikelihood for true params is {0}, best loglikelihood is {1}'.format(llh_trueparams, bestllh))\n",
    "print('true beta is {0}, recovered beta is {1}'.format(beta, bestparameters[0]))\n",
    "print('true alpha_pos is {0}, recovered alpha is {1}'.format(alpha_pos, bestparameters[1]))\n",
    "print('true alpha_neg is {0}, recovered alpha is {1}'.format(alpha_neg, bestparameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b07280",
   "metadata": {},
   "source": [
    "## Model-Fitting on Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed54eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Zaffs on Simple State-Action RL with 1 Alpha\n",
    "print('Non-Zaffs for Young Kids =============================')\n",
    "Data = aa_kids_young.loc[aa_kids_young.Block == aa_kids_young.BadBlocks, [\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")\n",
    "print('======================================================')\n",
    "\n",
    "print('Non-Zaffs for Older Kids =============================')\n",
    "Data = aa_kids_old.loc[aa_kids_old.Block == aa_kids_old.BadBlocks, [\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")\n",
    "print('======================================================')\n",
    "\n",
    "print('Non-Zaffs for Adults =================================')\n",
    "Data = aa_adults.loc[aa_adults.Block == aa_adults.BadBlocks, [\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee36d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple State-Action RL with 1 Alpha\n",
    "# Young Kids\n",
    "print('Young Kids =============================')\n",
    "Data = aa_kids_young[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")\n",
    "print('========================================')\n",
    "\n",
    "# Older Kids\n",
    "print('Older Kids =============================')\n",
    "Data = aa_kids_old[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")\n",
    "print('========================================')\n",
    "\n",
    "# Adults\n",
    "print('Adults =================================')\n",
    "Data = aa_adults[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "print()\n",
    "print('overall')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha is {0}'.format(bestparameters[1]))\n",
    "plot_llh_by_params(RL_StateAction_LLH, bounds, Data, \"contour\")\n",
    "print('========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Learning Rate for Young Kids, Older Kids, Adults\n",
    "betamin = 0\n",
    "betamax = 15\n",
    "alphamin = 0\n",
    "alphamax = 1\n",
    "bounds = [[betamin, betamax], [alphamin, alphamax], [alphamin, alphamax]]\n",
    "niter = 10\n",
    "\n",
    "Data = aa_kids_young[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL2a_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "\n",
    "print()\n",
    "print('Overall for Younger Kids ==================')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha positive is {0}'.format(bestparameters[1]))\n",
    "print('best alpha negative is {0}'.format(bestparameters[2]))\n",
    "print()\n",
    "\n",
    "Data = aa_kids_old[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL2a_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "\n",
    "print()\n",
    "print('Overall for Older Kids   ==================')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha positive is {0}'.format(bestparameters[1]))\n",
    "print('best alpha negative is {0}'.format(bestparameters[2]))\n",
    "print()\n",
    "\n",
    "Data = aa_adults[[\"PartID\", \"Trial\", \"AA\", \"Win\", \"Block\"]].to_numpy()\n",
    "bestparameters, bestllh = optimize(RL2a_StateAction_LLH, bounds, Data, niter, toplot=True, message=True)\n",
    "\n",
    "print()\n",
    "print('Overall for Adults       ==================')\n",
    "print('best loglikelihood is {0}'.format(bestllh))\n",
    "print('best beta is {0}'.format(bestparameters[0]))\n",
    "print('best alpha positive is {0}'.format(bestparameters[1]))\n",
    "print('best alpha negative is {0}'.format(bestparameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2bc74c",
   "metadata": {},
   "source": [
    "## Model Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e565844",
   "metadata": {},
   "source": [
    "## Additional Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837c12b",
   "metadata": {},
   "source": [
    "Non-Zaff Learning Comparison Across Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085acbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fe551957370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 444.625x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine the proportions of individuals that approach the non-zaffs across trial set per group\n",
    "\n",
    "dfs = [aa_kids_young, aa_kids_old, aa_adults]\n",
    "age_group = [\"Young Kid\", \"Older Kid\", \"Adult\"]\n",
    "\n",
    "for i in range(3): \n",
    "    df = dfs[i]\n",
    "    df = df.loc[df.Block == df.BadBlocks, [\"TrialSet\", \"AA\"]].groupby([\"TrialSet\"])\n",
    "    df = df.sum() / df.count()\n",
    "    df[\"AgeGroup\"] = age_group[i]\n",
    "    df.reset_index(inplace = True)\n",
    "    if i == 0: \n",
    "        all_df = df\n",
    "    else: \n",
    "        all_df = pd.concat([all_df, df])\n",
    "all_df.rename(columns = {\"AA\": \"Proportion of Approaching Non-Zaffs\"}, inplace = True)\n",
    "all_df.reset_index(inplace = True, drop = True)\n",
    "sns.relplot(\n",
    "    data = all_df, x = \"TrialSet\", y = \"Proportion of Approaching Non-Zaffs\", \n",
    "    kind = \"line\", hue = \"AgeGroup\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
